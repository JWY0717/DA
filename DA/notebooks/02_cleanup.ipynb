{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mmsi ship_name  ship_type   \n",
      "0  440051540      D-01          0  \\\n",
      "\n",
      "                                                geom    cog  sog   \n",
      "0  0101000020110F00000000002039676B41000000002DCF...  329.2  5.7  \\\n",
      "\n",
      "        insert_time  지방청           표지                일시   풍향   유향    기온    수온   \n",
      "0  2023-05-11 10:10  부산청  신항유도등부표(랜비)  2023-05-11 10:10  196  246  16.4  17.0  \\\n",
      "\n",
      "     풍속   유속    기압  습도  \n",
      "0  9.77  0.3  1017  82  \n"
     ]
    }
   ],
   "source": [
    "data = 'D:\\장우영\\LOCALSEARCH\\DA\\DA\\data\\FAmerge_20230518_124958.csv'\n",
    "\n",
    "merge_data = pd.read_csv(data, encoding='ANSI')\n",
    "#print(weather_data)\n",
    "print(merge_data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mmsi      ship_name  ship_type    cog   sog       insert_time   \n",
      "0      440051540           D-01          0  329.2   5.7  2023-05-11 10:10  \\\n",
      "1      440300780            NaN          0  329.8   0.0  2023-05-11 10:10   \n",
      "2      440208550            NaN          0  139.3   0.0  2023-05-11 10:10   \n",
      "3      440275000  GBK EXPRESS 1         40  175.8   0.0  2023-05-11 10:10   \n",
      "4      440414850   NO1 GEO SUNG         80    0.0   0.0  2023-05-11 10:10   \n",
      "...          ...            ...        ...    ...   ...               ...   \n",
      "16180  538010219  SAWASDEE VEGA         70  225.2  16.0  2023-05-11 10:29   \n",
      "16181  440121850            NaN          0    0.0   0.0  2023-05-11 10:30   \n",
      "16182  440110850  PILOT ORYUKDO         50  322.3   1.7  2023-05-11 10:30   \n",
      "16183  440107840   NO.7 GEUMHWA         30    0.0   0.0  2023-05-11 10:30   \n",
      "16184  440134620       HYUNJUNG         80  231.3   0.7  2023-05-11 10:30   \n",
      "\n",
      "        풍향    기온    수온     풍속   유속    기압  습도  \n",
      "0      196  16.4  17.0   9.77  0.3  1017  82  \n",
      "1      196  16.4  17.0   9.77  0.3  1017  82  \n",
      "2      196  16.4  17.0   9.77  0.3  1017  82  \n",
      "3      196  16.4  17.0   9.77  0.3  1017  82  \n",
      "4      196  16.4  17.0   9.77  0.3  1017  82  \n",
      "...    ...   ...   ...    ...  ...   ...  ..  \n",
      "16180  209  16.2  16.7  11.30  0.2  1017  82  \n",
      "16181  210  16.3  16.7  10.30  0.2  1017  83  \n",
      "16182  210  16.3  16.7  10.30  0.2  1017  83  \n",
      "16183  210  16.3  16.7  10.30  0.2  1017  83  \n",
      "16184  210  16.3  16.7  10.30  0.2  1017  83  \n",
      "\n",
      "[16185 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 교육 및 테스트 세트로 분할\n",
    "X = merge_data[[\"mmsi\",\"ship_name\",\"ship_type\",\"cog\",\"sog\",\"insert_time\",\"풍향\",\"기온\",\"수온\",\"풍속\",\"유속\",\"기압\",\"습도\"]]  # 입력 값 (excluding \"geom\")\n",
    "y = merge_data[\"geom\"]  # 출력 값 (geom)\n",
    "\n",
    "print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                 D-01\n",
      "1                  NaN\n",
      "2                  NaN\n",
      "3        GBK EXPRESS 1\n",
      "4         NO1 GEO SUNG\n",
      "             ...      \n",
      "16180    SAWASDEE VEGA\n",
      "16181              NaN\n",
      "16182    PILOT ORYUKDO\n",
      "16183     NO.7 GEUMHWA\n",
      "16184         HYUNJUNG\n",
      "Name: ship_name, Length: 16185, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merge_data[\"ship_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습용, 검증용, 시험용으로 분리\n",
    "train_size = int(327 * 0.8)\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size+33], y[train_size:train_size+33]\n",
    "X_test, y_test = X[train_size+33:], y[train_size+33:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_268\\3470333947.py\", line 8, in <module>\n",
      "    X_train = make_Tensor(X_train.to_numpy())\n",
      "  File \"C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_268\\3470333947.py\", line 6, in make_Tensor\n",
      "    return torch.from_numpy(array).float()\n",
      "TypeError: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygments\\style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygments\\style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#Tensor 형태로 변환\n",
    "import numpy as np\n",
    "\n",
    "def make_Tensor(array):\n",
    "    return torch.from_numpy(array).float()\n",
    "\n",
    "X_train = make_Tensor(X_train.to_numpy())\n",
    "y_train = make_Tensor(y_train.to_numpy())\n",
    "X_val = make_Tensor(X_val.to_numpy())\n",
    "y_val = make_Tensor(y_val.to_numpy())\n",
    "X_test = make_Tensor(X_test.to_numpy())\n",
    "y_test = make_Tensor(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_268\\3973625044.py\", line 22, in <module>\n",
      "    model.add(LSTM(128, input_shape=(X_train.shape[1])))\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 561, in __init__\n",
      "    super().__init__(\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\dropout_rnn_cell_mixin.py\", line 43, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\rnn\\base_rnn.py\", line 271, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 3790, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\", line 205, in _method_wrapper\n",
      "    result = method(self, *args, **kwargs)\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 453, in __init__\n",
      "    batch_input_shape = (batch_size,) + tuple(kwargs[\"input_shape\"])\n",
      "TypeError: 'int' object is not iterable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"C:\\Users\\SW\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygments\\style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pygments\\style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# 데이터 전처리\n",
    "# merge_data DataFrame을 사용하여 필요한 전처리를 수행합니다.\n",
    "# 필요한 전처리에는 NaN 값 처리, 범주형 변수 인코딩, 수치형 변수 스케일링 등이 포함될 수 있습니다.\n",
    "\n",
    "# 학습용, 검증용, 시험용으로 분할\n",
    "train_size = int(len(merge_data) * 0.8)\n",
    "val_size = int(len(merge_data) * 0.1)\n",
    "test_size = len(merge_data) - train_size - val_size\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
    "X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]\n",
    "\n",
    "# LSTM 모델 구축\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1])))\n",
    "model.add(Dense(2))  # 2개의 출력 뉴런: geom\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# 모델 평가\n",
    "train_loss = model.evaluate(X_train, y_train)\n",
    "val_loss = model.evaluate(X_val, y_val)\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Train Loss: {train_loss}, Val Loss: {val_loss}, Test Loss: {test_loss}\")\n",
    "\n",
    "# 예측\n",
    "next_location = model.predict(X_test[-1].reshape(1, X_test.shape[1], X_test.shape[2]))\n",
    "print(f\"Next location prediction (geom): {next_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
